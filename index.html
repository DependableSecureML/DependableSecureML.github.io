<html>
<head>
<link rel="stylesheet" type="text/css" href="/css/style.css" title="style1">
<link rel="icon" type="image/ico" href="/images/favico.ico">
<link href='https://fonts.googleapis.com/css?family=Open+Sans:300italic,300,700' rel='stylesheet' type='text/css'>
<link href="https://fonts.googleapis.com/css?family=Merriweather:400,700" rel="stylesheet">
<meta name="description" content="Dependable and Secure Machine Learning Workshop">
<meta name="keywords" content="dependable machine learning, secure machine learning, DSN workshops, DMSL">
<meta http-equiv="Content-Type" content="text/html"> 
<title>DSML 2018: Dependable and Secure Machine Learning</title>
</head>
<body bgcolor="#FFFFFF">
<div id="container">
<h1>DSML 2018<br><font size="16pt">Dependable&nbsp;and&nbsp;Secure&nbsp;Machine&nbsp;Learning</font></h1>
<center>
Co-located with the <a href="https://dsn2018.uni.lu/"><em> 48th IEEE/IFIP International Conference on Dependable Systems and Networks</em></a> (DSN 2018)<br>
Luxembourg City, 25&ndash;28 June 2018
</center>
<p>
</p>
<table width="100%">
<tr valign="top">
<td width="60%" valign="top">
<p>
Machine learning (ML) is increasingly used in critical domains such as health and wellness, criminal sentencing recommendations, commerce, transportation, human capital management, entertainment, and communication. The design of ML systems has mainly focused on developing models, algorithms, and datasets on which they are trained to demonstrate high accuracy for specific tasks such as object recognition and classification. Machine learning al¬go¬rithms typically construct a model by training on a labeled training dataset and their performance is assessed based on the accuracy in predicting labels for unseen (but often similar) testing data. This is based on the assumption that the training dataset is representative of the inputs that the system will face in deployment. However, in practice there are a wide variety of unexpected accidental, as well as adversarially-crafted, perturbations on the ML inputs that might lead to violations of this assumption. Further, ML algorithms are often executed on special-purpose hardware accelerators, which may themselves be subject to faults. Thus, there is a growing concern regarding the reliability, safety, security, and accountability of machine learning systems.

</p>
<p>
The DSML workshop is intended to provide an open forum for
researchers, practitioners, and the regulatory experts, to present and
discuss innovative ideas and practical techniques and tools for
producing dependable and secure ML systems. A major goal of the
workshop is to draw the attention of the research community to the
problem of establishing guarantees of reliability, security, safety,
and robustness for systems that incorporate increasingly complex
machine learning models, and to the challenge of determining whether
such systems can comply with requirements set by regulations and
standards for safety-critical systems.
</p>

Topics of interest include:
<ul> 
<li>Testing, certification, and verification of ML models and algorithms</li>
<li>Metrics for benchmarking the robustness of ML systems</li>
<li>Adversarial machine learning (attacks and defenses)</li>
<li>Resilient and repairable ML models and algorithms</li>
<li>Reliability and security of ML architectures, computing platforms, and distributed systems</li>
<li>Faults in implementation of ML algorithms and their consequences</li> 
<li>Dependability of ML accelerators and hardware platforms</li>
<li>Safety and societal impact of machine learning</li>


<!--
<center>
<img src="/images/luxembourg.jpg" width=650><br>
<font color="#CCCCCC">Image credit: <a href="https://commons.wikimedia.org/wiki/File:Luxembourg_Neum%C3%BCnster_und_Johanneskirche_(2232281937).jpg">Wolfgang Staudt</a></font>
</center>
-->

<h2>Organizers</h2>

<a href="http://faculty.virginia.edu/alemzadeh/">Homa Alemzadeh</a> (University of Virginia)<br>
<a href="http://blogs.ubc.ca/karthik/">Karthik Pattabiraman</a> (University of British Columbia)<br>
<a href="https://www.cs.virginia.edu/evans">David Evans</a> (University of Virginia)<br>

</td>
<td valign="top">
<center>
<img src="/images/alzetteriver.jpg" width="90%"><br>
<font size="-1" color="#CCCCCC">Image credit: Wolfgang Staugt</a></font>
</center>
</td>
</tr>
</table>


</body>
</html>



