<html>
<head>
<title>
DSML 2018: Dependable and Secure Machine Learning
</title>
</head>
<body>

<h1>DSML 2018: Dependable and Secure Machine Learning</h1>
<p>
Machine learning (ML) is increasingly used in critical domains such as
health and wellness, criminal sentencing recommendations, commerce,
transportation, human capital management, entertainment, and
communication. The design of ML systems has mainly focused on
developing models, algorithms, and datasets on which they are trained
to demonstrate high accuracy for specific tasks such as object
recognition and classification. However, in practice there are a wide
variety of unexpected accidental, as well as adversarially-crafted,
perturbations on the ML inputs that might lead to violations of this
assumption. Further, ML algorithms are often executed on
special-purpose hardware accelerators, which may themselves be subject
to faults. Thus, there is a growing concern regarding the reliability,
safety, security, and accountability of machine learning systems.
</p>
<p>
The DSML workshop is intended to provide an open forum for
researchers, practitioners, and the regulatory experts, to present and
discuss innovative ideas and practical techniques and tools for
producing dependable and secure ML systems. A major goal of the
workshop is to draw the attention of the research community to the
problem of establishing guarantees of reliability, security, safety,
and robustness for systems that incorporate increasingly complex
machine learning models, and to the challenge of determining whether
such systems can comply with requirements set by regulations and
standards for safety-critical systems.
</p>

<h2>Organizers</h2>

<a href="http://faculty.virginia.edu/alemzadeh/">Homa Alemzadeh</a> (University of Virginia)<br></br>
<a href="http://blogs.ubc.ca/karthik/">Karthik Pattabiraman</a> (University of British Columbia)<br></br>
<a href="https://www.cs.virginia.edu/evans">David Evans</a> (University of Virginia)<br></br>

</body>
</html>



