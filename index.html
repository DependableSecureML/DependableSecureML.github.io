<html>

<head>
    <link rel="stylesheet" type="text/css" href="css/style.css" title="style1">
    <link rel="icon" type="image/ico" href="images/favico.ico">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:300italic,300,700' rel='stylesheet' type='text/css'>
    <link href="https://fonts.googleapis.com/css?family=Merriweather:400,700" rel="stylesheet">
    <meta name="description" content="Dependable and Secure Machine Learning Workshop">
    <meta name="keywords" content="dependable machine learning, secure machine learning, DSN workshops, DMSL">
    <meta http-equiv="Content-Type" content="text/html">
    <title>DSML 2025: Dependable and Secure Machine Learning</title>
</head>

<body bgcolor="#FFFFFF">
    <div id="container">
        <table width="100%">
            <tr valign="top">
                <ul class="topnav">
                    <li><a class="active" href="#home">Home</a></li>
                    <li><a href="cfp.html">Call for Papers<br></a></li>
                    <li><a href="committee.html">Committees</a></li>
                    <li><a href="program.html">Workshop Program</a></li>
                    <li><a href="https://dsn2025.github.io/">Venue</a></li>
                    <!--li><a href="http://www.dsn.org/cs.html">Registration</a></li-->
                    <li><a href="previous.html">Previous Workshop Editions</a></li>
                </ul>
            </tr>
            <tr>
                <td><br></td>
            </tr>
            <tr valign="top">
                <td width="80%" valign="top" style="padding-bottom:20px">
                    <h1>DSML 2025<br>Dependable and Secure Machine Learning</h1>
                    <b>
                        June 23, 2025<br>
                        Co-located with the <a href="http://www.dsn.org"><em> 55th IEEE/IFIP International Conference on
                                Dependable Systems and Networks</em></a> (DSN 2025)<br>
                        Naples, Italy
                    </b>
                </td>
                <td valign="top" align="center">
                    <img src="images/2025.png" width="60%"><br>
                </td>
            </tr>
            <tr valign="top">
                <td width="80%" valign="top">

                    <!-- <p>
                    <h2>Important Announcement</h2>

                    <font color="red">Currently, we plan to have in-person workshop. Authors are expected to present in-person. We may allow remote present in exceptional case on a case by case basis. 
                        We are closely monitoring the ongoing COVID situation, and may change the format depending on DSN conference policies, government mandates and safety of the workshop attendants. 
                    Contact PC chairs if you have any questions!</font>
                    </p>-->

                    <p>
                        Machine learning (ML) is increasingly used in critical domains such as healthcare, criminal sentencing recommendations, commerce, transportation, entertainment, space technology, and communication. The design of traditional ML systems has mainly focused on developing models, algorithms, and datasets on which they are trained to demonstrate high accuracy for specific tasks such as object recognition and classification. Recent advances, such as Generative AI, have expanded ML capabilities to include generating realistic content like text, images, and videos, enabling new applications in creative industries, education, and personalized healthcare. 

                        ML algorithms typically construct a model by training on a labeled training dataset, and their performance is assessed based on the accuracy in predicting labels for unseen (but often similar) testing data. This is based on the assumption that the training dataset is representative of the inputs that the system will face in deployment. However, in practice, there are many unexpected accidental and adversarially-crafted perturbations on the ML inputs that might lead to violations of this assumption. Generative AI, while powerful, introduces new risks, such as the generation of highly convincing adversarial inputs or misinformation, which can mislead the system decision during training or evaluation and undermine the overall reliability and safety.

                        Moreover, ML algorithms are also often over-confident about their predictions when processing anomalous or unexpected inputs. This makes it difficult to deploy them in safety-critical settings where one needs to rely on ML predictions to make decisions or revert to a failsafe mode. Further, ML algorithms are often executed on special-purpose hardware accelerators, which could be subject to faults and attacks. Thus, there is a growing concern regarding the reliability, safety, security & privacy, and accountability of ML-assisted systems.

                    </p>

                    <p>
                        The DSML workshop is an open forum for researchers, practitioners, and regulatory experts, to present and discuss innovative ideas and practical techniques and tools for producing dependable and secure ML systems. A major goal of the workshop is to draw the attention of the research community to the problem of establishing guarantees of reliability, security, safety, and robustness for systems that incorporate increasingly complex machine learning models, and to the challenge of determining whether such systems comply with the requirements set by regulations, and standards for safety-critical systems. A further goal is to build a research community at the intersection of ML systems and dependable and secure computing. 
                    </p>

                    <iframe src="images/dsml25-cfp.pdf" width="100%" height="600px"></iframe> <br>

                <td valign="top">

               

                    <!-- <center>
<img src="images/2025.jpg" width="55%"><br>
<font size="-1" color="#CCCCCC">Image credit: Wolfgang Staugt</a></font>
</center> -->

                </td>
            </tr>
        </table>
    </div>
</body>

</html>
