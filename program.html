<html>
<head>
<link rel="stylesheet" type="text/css" href="css/style.css" title="style1">
<link rel="icon" type="image/ico" href="images/favico.ico">
<link href='https://fonts.googleapis.com/css?family=Open+Sans:300italic,300,700' rel='stylesheet' type='text/css'>
<link href="https://fonts.googleapis.com/css?family=Merriweather:400,700" rel="stylesheet">
<meta name="description" content="Dependable and Secure Machine Learning Workshop">
<meta name="keywords" content="dependable machine learning, secure machine learning, DSN workshops, DMSL">
<meta http-equiv="Content-Type" content="text/html"> 
<title>DSML 2020: Dependable and Secure Machine Learning</title>
</head>

<body bgcolor="#FFFFFF">
<div id="container">
<table width="100%">
<tr valign="top">
<ul class="topnav">
<li><a href="index.html">Home</a></li>
<li><a href="cfp.html">Call for Papers<br></a></li>
<li><a href="committee.html">Committees</a></li>
<li><a class="active" href="program.html">Workshop Program</a></li>
<li><a href="http://www.dsn.org/cvvenue.html">Venue</a></li>
<li><a href="http://www.dsn.org/cs.html">Registration</a></li>
<li><a href="./2018/index.html">DSML 2018</a></li>
<li><a href="./2019/index.html">DSML 2018</a></li>
</ul>
</tr>
<tr><td><br></td></tr>
<tr valign="top">
<td width="80%" valign="top" style="padding-bottom:20px">
<h1>DSML 2020<br>Dependable and Secure Machine Learning</h1>
</td>
<td valign="top" align="center">
<img src="images/2020.jpg" width="60%"><br>
</td>
</tr>
<tr valign="top">
<td width="70%" valign="top">
<h2>Workshop Program - Monday, 29 June 2020</h2>
<table cellpadding="0" cellspacing="0" class="c12" width="950">
<tbody>
  <tr> 
	<td class="c10 c11"><span class="c2">TBA</span></td>
	<td class="c9 c11"><span class="c8 c2">Welcome to DSN-DSML 2020</span><br>
    <span class="c2 c3 d2">Homa Alemzadeh, University of Virginia</span>
    </td>
  </tr>
  <tr>
	<td class="c7 c13"><span class="c2">  </span></td>
	<td class="c9 c13"><span class="c8 c2">Session 1: Keynote Talk</span><br>
	<span class="c2 c3 d2">Session Chair: TBA</span>
	</td>
  </tr>
  <tr>
	<td class="c10"><span class="c2"></span>
	  <span class="c2">TBA</span>
	  <br><br><span class="c2">TBA</span>
	</td>
	<td class="c9">
	  <span class="c8 c2"><a href = "#keynotes">TBA</a></span><br>
	  <span class="c2 c3 d2">	<a href="https://www.cse.cuhk.edu.hk/lyu/home">Michael Lyu</a>, Chinese University of Hong Kong<br/>
    Q&A</span>
	</td>
  </tr>

  <tr>
	<td class="c7"><span class="c2">TBA</span></td>
	<td class="c9 c11"><span class="c8 c2">Break</span></td>
  </tr>
  
  <tr>
	<td class="c7 c13"><span class="c2">  </span></td>
	<td class="c9 c13"><span class="c8 c2">Session 2: Attacks</span> <br>
	<span class="c2 c3 d2">Session Chair: TBA</span>
	</td>
  </tr>
  <tr>
	<td class="c10"><span class="c2"></span>
	  <span class="c2">TBA</span>
	  <br><br><br><span class="c2">TBA</span>
	  <br><br><br><span class="c2">TBA</span>
	</td>
	<td class="c9">
	  <!--<span class="c8 c2"><a href = "papers/dsn-dsml19-final20.pdf">Adversarial Video Captioning</a></span><br />-->
	  <span class="c8 c2">TAaMR: Targeted Adversarial Attack against Multimedia Recommender Systems </span><br />
	  <span class="c2 c3 d2">Tommaso Di Noia, Daniele Malitesta, Felice Antonio Merra</span>
	  <br style="margin-bottom:1pt;"><br/>

	  <!--<span class="c8 c2"><a href = "papers/dsn-dsml19-paper13.pdf">Universal Adversarial Perturbations for Speech Recognition Systems</a></span><br/>-->
	  <span class="c8 c2">On The Generation Of Unrestricted Adversarial Examples</span><br/>
	  <span class="c2 c3 d2">Mehrgan Khoshpasand, Ali Ghorbani</span>
	  <br style="margin-bottom:1pt;"><br/>

	  <!--<span class="c8 c2"><a href = "papers/dsn-dsml19-paper10.pdf">Malware Evasion Attack and Defense</a></span><br /><-->
	  <span class="c8 c2">Blackbox Attacks on Reinforcement Learning Agents Using Approximated Temporal Information</span><br />
	  <span class="c2 c3 d2">Yiren Zhao, Ilia Shumailov, Han Cui, Xitong Gao, Robert Mullins, Ross Anderson</span>	  
	  <br style="margin-bottom:1pt;"><br/>
  
	</td>
  </tr>
  <tr>
	<td class="c7"><span class="c2">TBA</span></td>
	<td class="c9 c11"><span class="c8 c2">Break</span></td>
  </tr>
  
  <tr>
	<td class="c7 c13"><span class="c2">  </span></td>
	<td class="c9 c13"><span class="c8 c2">Session 3: Validation, Verification, and Defense</span> <br> 
	<span class="c2 c3 d2">Session Chair: TBA</span>
	</td>
  </tr>
	<td class="c10"><span class="c2"></span>
	  <span class="c2">TBA</span>
	  <br><br><br><span class="c2">TBA</span>
	  <br><br><br><span class="c2">TBA</span>
	</td>
	<td class="c9">
	  <!--<span class="c8 c2"><a href = "papers/dsn-dsml19-paper2.pdf">NV-DNN: Towards Fault-Tolerant DNN Systems with N-Version Programming</a></span><br />-->
	  <span class="c8 c2">PyTorchFI: A Runtime Perturbation Tool for DNNs</span><br />
	  <span class="c2 c3 d2">Abdulrahman Mahmoud, Neeraj Aggarwal, Alex Nobbe, Jose Rodrigo Sanchez Vicarte, Sarita Adve, Christopher W. Fletcher, Iuri Frosio, Siva Kumar Sastry Hari</span>
	  <br style="margin-bottom:1pt;"><br/>

	  <!--<span class="c8 c2"><a href = "papers/dsn-dsml19-paper11.pdf">N-version Machine Learning Models for Safety Critical Systems</a></span><br>-->
	  <span class="c8 c2">Online Verification through Model Checking of Medical Critical Intelligent Systems</span><br>
	  <span class="c2 c3 d2">João Martins, Raul Barbosa, Nuno Lourenço, Jacques Robin, Henrique Madeira</span>
	  <br style="margin-bottom:1pt;"><br/>
	  
	  <!--<span class="c8 c2"><a href = "papers/dsn-dsml19-paper9.pdf">Novelty Detection via Network Saliency in Visual-based Deep Learning </a></span><br>-->
	  <span class="c8 c2">BlurNet: Defense by Filtering the Feature Maps</span><br>
	  <span class="c2 c3 d2">Ravi Raju, Mikko Lipasti</span>
	  <br style="margin-bottom:1pt;"><br/>
	  
	</td>
  </tr>
  
  <tr>
	<td class="c7"><span class="c2">15:40-16:00</span></td>
	<td class="c9 c11"><span class="c8 c2">Break</span></td>
  </tr>

  <tr>
	<td class="c7 c13"><span class="c2">  </span></td>
	<td class="c9 c13"><span class="c8 c2">Session 4: Keynote Talk</span><br>
	<span class="c2 c3 d2">Session Chair: TBA</span>
	</td>
  </tr>
  <tr>
	<td class="c10"><span class="c2"></span>
	  <span class="c2">16:00-17:00</span>
	  <br><br><span class="c2">17:00-17:15</span>
	</td>
	<td class="c9">
		  <span class="c8 c2"><a href = "#keynotes"> TBA </a></span><br>
	  <span class="c2 c3 d2"><a href="https://www.linkedin.com/in/rajarshigupta">Rajarshi Gupta</a>, Avast Security<br/>
	Q&A</span>
	</td>
  </tr>
  
  <tr> 
	<td class="c10 c11"><span class="c2">TBA</span></td>
	<td class="c9 c11"><span class="c8 c2">Discussion and Closing</span></td>
  </tr>

<!--	
<tr>
</tbody>
</table>
</td>
</tr>
<tr><td><br></td></tr>

<tr valign="top">
<td width="70%" valign="top">
	
<h2><a id="keynotes">Keynotes</a></h2>
<p>
<table border="0" cellpadding="0" cellspacing="0">
	<tbody font-weight: bold;>
	<tr>
    <img src="images/JasonMartin.jpg" width="15%"><br>
	<b>Machine Learning Security & Privacy - An Industry Perspective</b><br>
	<a href="https://www.intel.ai/bio/jason-martin/"> Jason Martin</a>, Intel Security Solutions Lab
    <br><br>
    <b>Abstract:</b> Threats follow value. This phenomenon has driven security needs for thousands of years, and information security is no different. Machine learning technologies promise to unlock the value of data, including high risk (ADAS), high reward (finance), and personal (biometric) computing, requiring us to protect that emerging value from new threats. In this talk I will describe our approach to threat modeling machine learning systems and how those threat models have led to our machine learning security and privacy research projects.
    <br><br>
    <b>Speaker Bio:</b> Jason Martin is a Senior Staff Research Scientist in the Security Solutions Lab and manager of the Secure Intelligence Team at Intel Labs. He leads a team of diverse researchers to investigate machine learning security in a way that incorporates the latest research findings and Intel products. Jason’s interests include machine learning, authentication and identity, trusted execution technology, wearable computing, mobile security, and privacy. Prior to Intel labs he spent several years as a security researcher performing security evaluations and penetration tests on Intel’s products. Jason is a co-inventor on 19 patents and received his BS in Computer Science from the University of Illinois at Urbana-Champaign.<br><br>
	</tr>

	<tr>
	<img src="https://people.eecs.berkeley.edu/%7Esseshia/images/sanjit_seshia.jpg" width="15%"><br>
    <b>Towards Verified Artificial Intelligence</b><br>
	<a href="http://people.eecs.berkeley.edu/~sseshia/">Sanjit A. Seshia</a>, University of California, Berkeley
    <br><br>
    <b>Abstract:</b> The deployment of artificial intelligence (AI), particularly of systems
that learn from data and experience, is rapidly expanding in our society. 
Verified artificial intelligence (AI) is the goal of designing AI-based 
systems that have strong, verified assurances of correctness with 
respect to mathematically-specified requirements. In this talk, I will 
consider Verified AI from a formal methods perspective. I will describe five 
challenges for achieving Verified AI, and five corresponding principles 
for addressing these challenges. I will illustrate these challenges
and principles with examples and sample results from the domain of
intelligent cyber-physical systems, with a particular focus on autonomous vehicles.<br><br>

		
		<b>Speaker Bio:</b> Sanjit A. Seshia is a Professor in the Department of Electrical Engineering
and Computer Sciences at the University of California, Berkeley. He received
an M.S. and Ph.D. in Computer Science from Carnegie Mellon University, and a
B.Tech. in Computer Science and Engineering from the Indian Institute of
Technology, Bombay. His research interests are in formal methods for
dependable and secure computing, with a current focus on the areas of
cyber-physical systems, computer security, and robotics. He has made
pioneering contributions to the areas of satisfiability modulo theories (SMT),
SMT-based verification, and inductive program synthesis. He is co-author of a
widely-used textbook on embedded, cyber-physical systems and has led the
development of technologies for cyber-physical systems education based on
formal methods. His awards and honors include a Presidential Early Career
Award for Scientists and Engineers (PECASE), an Alfred P. Sloan Research
Fellowship, and the Frederick Emmons Terman Award for contributions to
electrical engineering and computer science education. He is a Fellow of the IEEE.<br><br>
    </tr>

	</tbody>
</table>
</td>
<td rowspan=3>
<!--<center>
<img src="images/alzetteriver.jpg" width="55%"><br>
<font size="-1" color="#CCCCCC">Image credit: Wolfgang Staugt</a></font>
</center>
</td>
</tr>
-->
</table>
</div>
</body>
</html>



