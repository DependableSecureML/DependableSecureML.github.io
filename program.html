<html>
<head>
<link rel="stylesheet" type="text/css" href="css/style.css" title="style1">
<link rel="icon" type="image/ico" href="images/favico.ico">
<link href='https://fonts.googleapis.com/css?family=Open+Sans:300italic,300,700' rel='stylesheet' type='text/css'>
<link href="https://fonts.googleapis.com/css?family=Merriweather:400,700" rel="stylesheet">
<meta name="description" content="Dependable and Secure Machine Learning Workshop">
<meta name="keywords" content="dependable machine learning, secure machine learning, DSN workshops, DMSL">
<meta http-equiv="Content-Type" content="text/html"> 
<title>DSML 2020: Dependable and Secure Machine Learning</title>
</head>

<body bgcolor="#FFFFFF">
<div id="container">
<table width="100%">
<tr valign="top">
<ul class="topnav">
<li><a href="index.html">Home</a></li>
<li><a href="cfp.html">Call for Papers<br></a></li>
<li><a href="committee.html">Committees</a></li>
<li><a class="active" href="program.html">Workshop Program</a></li>
<li><a href="http://www.dsn.org/cvvenue.html">Venue</a></li>
<li><a href="http://www.dsn.org/cs.html">Registration</a></li>
<li><a href="./2018/index.html">DSML 2018</a></li>
<li><a href="./2019/index.html">DSML 2018</a></li>
</ul>
</tr>
<tr><td><br></td></tr>
<tr valign="top">
<td width="80%" valign="top" style="padding-bottom:20px">
<h1>DSML 2020<br>Dependable and Secure Machine Learning</h1>
</td>
<td valign="top" align="center">
<img src="images/2020.jpg" width="60%"><br>
</td>
</tr>
<tr valign="top">
<td width="70%" valign="top">
<h2>Workshop Program - Monday, 29 June 2020</h2>
<table cellpadding="0" cellspacing="0" class="c12" width="950">
<tbody>
  <tr> 
	<td class="c10 c11"><span class="c2">15:00 CET</span></td>
	<td class="c9 c11"><span class="c8 c2">Welcome to DSN-DSML 2020</span><br>
    <span class="c2 c3 d2">Homa Alemzadeh, University of Virginia</span>
    </td>
  </tr>
  <tr>
	<td class="c7 c13"><span class="c2">  </span></td>
	<td class="c9 c13"><span class="c8 c2">Session 1: Keynote Talk</span><br>
	<span class="c2 c3 d2">Session Chair: Karthik Pattabiraman, University of British Columbia</span>
	</td>
  </tr>
  <tr>
	<td class="c10"><span class="c2"></span>
	  <span class="c2">15:05 CET</span>
	  <br><br><span class="c2">15:35 CET</span>
	</td>
	<td class="c9">
	  <span class="c8 c2"><a href = "#keynotes">Interpretability-Driven Dependable and Secure Machine Learning</a></span><br>
	  <span class="c2 c3 d2">	<a href="https://www.cse.cuhk.edu.hk/lyu/home">Michael Lyu</a>, Chinese University of Hong Kong<br/>
    Q&A</span>
	</td>
  </tr>

  <tr>
	<td class="c7"><span class="c2">15:45 CET</span></td>
	<td class="c9 c11"><span class="c8 c2">Break</span></td>
  </tr>
  
  <tr>
	<td class="c7 c13"><span class="c2">  </span></td>
	<td class="c9 c13"><span class="c8 c2">Session 2: Attacks</span> <br>
	<span class="c2 c3 d2">Session Chair: Varun Chandrasekaran, University of Wisconsin-Madison</span>
	</td>
  </tr>
  <tr>
	<td class="c10"><span class="c2"></span>
	  <span class="c2">15:55 CET</span>
	  <br><br><br><span class="c2">16:10 CET</span>
	  <br><br><br><span class="c2">16:25 CET</span>
	</td>
	<td class="c9">
	  <!--<span class="c8 c2"><a href = "papers/dsn-dsml19-final20.pdf">Adversarial Video Captioning</a></span><br />-->
	  <span class="c8 c2">TAaMR: Targeted Adversarial Attack against Multimedia Recommender Systems </span><br />
	  <span class="c2 c3 d2">Tommaso Di Noia, Daniele Malitesta, Felice Antonio Merra</span>
	  <br style="margin-bottom:1pt;"><br/>

	  <!--<span class="c8 c2"><a href = "papers/dsn-dsml19-paper13.pdf">Universal Adversarial Perturbations for Speech Recognition Systems</a></span><br/>-->
	  <span class="c8 c2">On The Generation Of Unrestricted Adversarial Examples</span><br/>
	  <span class="c2 c3 d2">Mehrgan Khoshpasand, Ali Ghorbani</span>
	  <br style="margin-bottom:1pt;"><br/>

	  <!--<span class="c8 c2"><a href = "papers/dsn-dsml19-paper10.pdf">Malware Evasion Attack and Defense</a></span><br /><-->
	  <span class="c8 c2">Blackbox Attacks on Reinforcement Learning Agents Using Approximated Temporal Information</span><br />
	  <span class="c2 c3 d2">Yiren Zhao, Ilia Shumailov, Han Cui, Xitong Gao, Robert Mullins, Ross Anderson</span>	  
	  <br style="margin-bottom:1pt;"><br/>
  
	</td>
  </tr>
  <tr>
	<td class="c7"><span class="c2">16:40 CET</span></td>
	<td class="c9 c11"><span class="c8 c2">Break</span></td>
  </tr>
  
  <tr>
	<td class="c7 c13"><span class="c2">  </span></td>
	<td class="c9 c13"><span class="c8 c2">Session 3: Validation, Verification, and Defense</span> <br> 
	<span class="c2 c3 d2">Session Chair: Florian Tram&#232;r, Stanford University</span>
	</td>
  </tr>
	<td class="c10"><span class="c2"></span>
	  <span class="c2">16:50 CET</span>
	  <br><br><br><span class="c2">17:05 CET</span>
	  <br><br><br><span class="c2">17:20 CET</span>
	</td>
	<td class="c9">
	  <!--<span class="c8 c2"><a href = "papers/dsn-dsml19-paper2.pdf">NV-DNN: Towards Fault-Tolerant DNN Systems with N-Version Programming</a></span><br />-->
	  <span class="c8 c2">PyTorchFI: A Runtime Perturbation Tool for DNNs</span><br />
	  <span class="c2 c3 d2">Abdulrahman Mahmoud, Neeraj Aggarwal, Alex Nobbe, Jose Rodrigo Sanchez Vicarte, Sarita Adve, Christopher W. Fletcher, Iuri Frosio, Siva Kumar Sastry Hari</span>
	  <br style="margin-bottom:1pt;"><br/>

	  <!--<span class="c8 c2"><a href = "papers/dsn-dsml19-paper11.pdf">N-version Machine Learning Models for Safety Critical Systems</a></span><br>-->
	  <span class="c8 c2">Online Verification through Model Checking of Medical Critical Intelligent Systems</span><br>
	  <span class="c2 c3 d2">João Martins, Raul Barbosa, Nuno Lourenço, Jacques Robin, Henrique Madeira</span>
	  <br style="margin-bottom:1pt;"><br/>
	  
	  <!--<span class="c8 c2"><a href = "papers/dsn-dsml19-paper9.pdf">Novelty Detection via Network Saliency in Visual-based Deep Learning </a></span><br>-->
	  <span class="c8 c2">BlurNet: Defense by Filtering the Feature Maps</span><br>
	  <span class="c2 c3 d2">Ravi Raju, Mikko Lipasti</span>
	  <br style="margin-bottom:1pt;"><br/>
	  
	</td>
  </tr>
  
  <tr>
	<td class="c7"><span class="c2">17:35 CET</span></td>
	<td class="c9 c11"><span class="c8 c2">Break</span></td>
  </tr>
	
  <tr>
	<td class="c7 c13"><span class="c2">  </span></td>
	<td class="c9 c13"><span class="c8 c2">Session 4: Keynote Talk</span><br>
	<span class="c2 c3 d2">Session Chair: Nicolas Papernot, University of Toronto & Vector Institute</span>
	</td>
  </tr>
  <tr>
	<td class="c10"><span class="c2"></span>
	  <span class="c2">17:45 CET</span>
	  <br><br><span class="c2">18:15 CET</span>
	</td>
	<td class="c9">
		  <span class="c8 c2"><a href = "#keynotes"> Using Secure AI to Secure Real Users (435M of them) </a></span><br>
	  <span class="c2 c3 d2"><a href="https://www.linkedin.com/in/rajarshigupta">Rajarshi Gupta</a>, Avast Security<br/>
	Q&A</span>
	</td>
  </tr>
  
  <tr> 
	<td class="c10 c11"><span class="c2">18:25 CET</span></td>
	<td class="c9 c11"><span class="c8 c2">Discussion and Closing</span></td>
  </tr>

<tr>
</tbody>
</table>
</td>
</tr>
<tr><td><br></td></tr>

<tr valign="top">
<td width="70%" valign="top">
	
<h2><a id="keynotes">Keynotes</a></h2>
<p>

	
<table border="0" cellpadding="0" cellspacing="0">
<tbody font-weight: bold;>
<tr>
<img src="images/Michael.jpg" width="15%"><br>
<b>Interpretability-Driven Dependable and Secure Machine Learning</b><br>
<a href="https://www.cse.cuhk.edu.hk/lyu/home"> Michael Lyu</a>, Chinese University Of Hong Kong
<br>
<br>
<b>Abstract:</b> 

Although artificial intelligence has advanced the state-of-the-art in many domains, its interpretability, 
	dependability, and security remain unsatisfactory, hindering the rapid deployment in many safety-critical scenarios. 
	Among these characteristics, interpretability is at the core since the human trust builds upon the interpretability 
	of model predictions and understanding of unexpected behaviors (e.g., error predictions, adversarial attacks). 
	In this talk, I will introduce some of our recent investigations on model interpretability in both natural 
	language processing and computer vision domains. Besides, I will illustrate our recent attempts on 
	dependable and secure machine learning from the interpretability perspective. 
	Finally, I will share some thoughts on the related research directions.
<br>
<br>
<b>Speaker Bio:</b> Michael R. Lyu is a Professor and the Chairman in the Computer Science & Engineering Department at the 
	Chinese University of Hong Kong. He received a B.S. in Electrical Engineering from the National Taiwan University, 
	an M.S. in Electrical and Computer Engineering from University of California, Santa Barbara, and a Ph.D. 
	in Computer Science from University of California, Los Angeles. His research interests include software 
	reliability engineering, dependable computing, machine learning, artificial intelligence, and distributed systems. 
	He published a widely cited McGraw-Hill Handbook of Software Reliability Engineering, and a Wiley book on 
	Software Fault Tolerance. He is a Fellow of the IEEE, a Fellow of ACM, a Fellow of AAAS, and an 
	IEEE Reliability Society Engineer of the Year.  He also appears in The AI 
	2000 Most Influential Scholars Annual List in 2020.
<br>
<br>
</tr>

<tr>
<img src="images/Rajarshi.jpg" width="15%"><br>
<b>Using Secure AI to Secure Real Users (435M of them)</b><br>
<a href="https://www.linkedin.com/in/rajarshigupta">Rajarshi Gupta</a>, Avast
<br>
<br>
<b>Abstract:</b> Recent years have seen heavy utilization of AI in security, 
but the complexities of a massively scalable production-quality security pipeline is often hard to grasp. 
In this seminar, we will discuss state-of-the-art AI techniques used to deter daily attacks, 
by drawing from experience of protecting 435M users (across PCs, mobiles, IoTs) at Avast. 
We will also identify gaps that exist between academic research in AI-Security, 
and the daily challenges of real-world attacker-defender contests. 
Finally, we suggest ways to bridge those gaps, 
to make the academic research more viable and valuable in real deployments.
<br>
<br>
<b>Speaker Bio:</b> Rajarshi Gupta is the Head of AI at Avast Software, the largest consumer security companies in the world. 
He has a PhD in EECS from UC Berkeley and has built a unique expertise at the intersection of Artificial Intelligence, 
Cybersecurity and Networking. 
Prior to joining Avast, Rajarshi worked for many years at Qualcomm Research, where he created ‘Snapdragon Smart Protect’,
the first ever product to achieve On-Device Machine Learning for Security. 
Rajarshi has authored over 200 issued U.S. Patents, and is featured on the wikipedia page for most prolific inventors in history.
<br>
<br>
</tr>
</tbody>
</table>
</td>
<td rowspan=3>

<!--<center>
<img src="images/alzetteriver.jpg" width="55%"><br>
<font size="-1" color="#CCCCCC">Image credit: Wolfgang Staugt</a></font>
</center>
</td>
</tr>
-->

</table>
</div>
</body>
</html>



