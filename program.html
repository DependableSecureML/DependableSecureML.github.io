<html>

<head>
<link rel="stylesheet" type="text/css" href="css/style.css" title="style1">
<link rel="icon" type="image/ico" href="images/favico.ico">
<link href='https://fonts.googleapis.com/css?family=Open+Sans:300italic,300,700' rel='stylesheet' type='text/css'>
<link href="https://fonts.googleapis.com/css?family=Merriweather:400,700" rel="stylesheet">
<meta name="description" content="Dependable and Secure Machine Learning Workshop">
<meta name="keywords" content="dependable machine learning, secure machine learning, DSN workshops, DMSL">
<meta http-equiv="Content-Type" content="text/html">
<title>DSML 2024: Dependable and Secure Machine Learning</title>
</head>

<body bgcolor="#FFFFFF">
<div id="container">
<table width="100%">
<tr valign="top">
<ul class="topnav">
<li><a href="index.html">Home</a></li>
<li><a href="cfp.html">Call for Papers<br></a></li>
<li><a href="committee.html">Committees</a></li>
<li><a class="active" href="program.html">Workshop Program</a></li>
<li><a href="https://dsn2024uq.github.io/">Venue</a></li>
<!--li><a href="https://dsn2023.dei.uc.pt/">Registration</a></li-->
<li><a href="previous.html">Previous Workshop Editions</a></li>
</ul>
</tr>
<tr>
<td><br></td>
</tr>
<tr valign="top">
<td width="80%" valign="top" style="padding-bottom:20px">
<h1>DSML 2024<br>Dependable and Secure Machine Learning</h1>
</td>
<td valign="top" align="center">
<img src="images/2024.png" width="60%"><br>
</td>
</tr>

<tr valign="top">
<td width="70%" valign="top">

<h2>Workshop Program</h2>

<table cellpadding="0" cellspacing="0" class="c12" width="1200">
<tbody>
<tr>
<td class="c10 c11"><span class="c2">9:00 AEST</span></td>
<td class="c9 c11"><span class="c8 c2">Welcome to DSN-DSML 2024</span><br>
</td>
</tr>

<tr>
<td class="c7 c13"><span class="c2"> </span></td>
<td class="c9 c13"><span class="c8 c2">Session 1: Keynote Talk</span><br>
</td>
</tr>

<tr>
<td class="c10"><span class="c2"></span>
<span class="c2">09:15 AEST</span>
<br><br><span class="c2">10:15 AEST</span>
</td>
<td class="c9">
<span class="c8 c2"><a href="#keynotes">From Neural Network Verification to Formal Verification for Neuro-Symbolic Artificial Intelligence (AI)</a></span><br>
<span class="c2 c3 d2"><a href="http://www.taylortjohnson.com/"> Taylor T. Johnson</a>, Associate Professor, Computer Science, Vanderbilt University, USA<br />
Q&A
</span>
</td>
</tr>

<tr>
<td class="c7"><span class="c2">10:30 AEST</span></td>
<td class="c9 c11"><span class="c8 c2">Coffee Break</span></td>
</tr>

<tr>
<td class="c7 c13"><span class="c2"> </span></td>
<td class="c9 c13"><span class="c8 c2">Session 2: Defense Mechanisms for Secure ML Systems</span>
    (Session Chair: <a href="https://blogs.ubc.ca/karthik/" target="_blank">Karthik Pattabiraman</a>)
<br>
</td>
</tr>
<tr>
<td class="c10"><span class="c2"></span>
<span class="c2">11:00 AEST</span>
<br><br><br><br><span class="c2">11:25 AEST</span>
<br><br><br><br><span class="c2">11:50 AEST</span>
</td>
<td class="c9">
<span class="c8 c2"><a>Adversarial Patch Detection: Leveraging Depth Contrast for Enhanced Threat Visibility</a></span><br />
<span class="c2 c3 d2">Niklas Bunzel, Jannis Hamborg</span><br />

<br style="margin-bottom:1pt;"><br />

<span class="c8 c2"><a>Unlearning Backdoor Attacks through Gradient-Based Model Pruning</a></span><br />
<span class="c2 c3 d2">Kealan Dunnett, Reza Arablouei, Dimity Miller, Volkan Dedeoglu, Raja Jurdak</span><br />
<br style="margin-bottom:1pt;"><br />

<span class="c8 c2"><a>Universal Soldier: Using Universal Adversarial Perturbations for Detecting Backdoor Attacks</a></span><br>
<span class="c2 c3 d2">Xiaoyun Xu, Oguzhan Ersoy, Hamidreza Tajalli, Stjepan Picek</span><br />
<br style="margin-bottom:1pt;"><br />

</td>
</tr>

<tr>
<td class="c7"><span class="c2">12:15 AEST</span></td>
<td class="c9 c11"><span class="c8 c2">Lunch Break</span></td>
</tr>

<tr>
<td class="c7 c13"><span class="c2"> </span></td>
<td class="c9 c13"><span class="c8 c2">Session 3: Keynote Talk</span><br>
</td>
</tr>
	
<tr>
<td class="c10"><span class="c2"></span>
<span class="c2">13:30 AEST</span>
<br><br><span class="c2">14:30 AEST</span>
</td>
<td class="c9">
<span class="c8 c2"><a href="#keynotes">Machine Learning for Privacy Compliance in Software Ecosystems</a> </span><br>
<span class="c2 c3 d2"><a href="https://baigd.github.io/">Guangdong Bai</a>, Associate Professor, The University of Queensland, Australia<br>
Q&A
</span>
</td>
</tr>


<tr>
<td class="c7 c13"><span class="c2"> </span></td>
<td class="c9 c13"><span class="c8 c2">Session 4: Dependable and Reliable ML Systems</span>
    (Session Chair: <a href="https://lishanyang.github.io/" target="_blank">Lishan Yang</a>)
<br>
</td>
</tr>
<tr>
<td class="c10"><span class="c2"></span>
<span class="c2">14:45 AEST</span>
<br><br><br><br><span class="c2">15:10 AEST</span>
<br><br><br><br><span class="c2">15:30 AEST</span>
</td>
<td class="c9">
<span class="c8 c2"><a>TrustDDL: A Privacy-Preserving Byzantine-Robust Distributed Deep Learning Framework</a></span><br />
<span class="c2 c3 d2">René Klaus Nikiel, Meghdad Mirabi, Carsten Binnig</span><br />

<br style="margin-bottom:1pt;"><br />

<span class="c8 c2"><a>Measuring the Effects of Environmental Influences on Object Detection</a></span><br />
<span class="c2 c3 d2">Niklas Bunzel, Michael Geißler, Gerrit Klause</span><br />
<br style="margin-bottom:1pt;"><br />

<span class="c8 c2"><a>Hybrid Convolutional Neural Networks with Reliabality Guarantee</a></span><br />
<span class="c2 c3 d2">Hans Dermot Doran, Suzana Veljanovska</span><br />
<br style="margin-bottom:1pt;"><br />

</td>
</tr>
<tr>
<td class="c7"><span class="c2">15:50 AEST</span></td>
<td class="c9 c11"><span class="c8 c2">Coffee Break</span></td>
</tr>


<tr>
<td class="c7 c13"><span class="c2"> </span></td>
<td class="c9 c13"><span class="c8 c2">Session 5: ML Systems for Security and Beyond</span>
    (Session Chair: <a href="https://sanghyun-hong.com/" target="_blank">Sanghyun Hong</a>)
<br>
</td>
</tr>
<tr>
<td class="c10"><span class="c2"></span>
<span class="c2">16:20 AEST</span>
<br><br><br><br><span class="c2">16:45 AEST</span>
<br><br><br><br><span class="c2">17:00 AEST</span>
</td>
<td class="c9">
<span class="c8 c2"><a>Intrusion Detection Systems using Quantum-Inspired Density Matrix Encodings</a></span><br />
<span class="c2 c3 d2">Larry Huynh, Jin B. Hong, Hajime Suzuki, Ajmal Mian, Seyit Camtepe</span><br />

<br style="margin-bottom:1pt;"><br />

<span class="c8 c2"><a>A Fault Diagnosis Method for Analog Circuits Based on Task Transfer Learning</a></span><br />
<span class="c2 c3 d2">Zhongyu Gao, Xiaoqing Wen, Aibin Yan </span><br />
<br style="margin-bottom:1pt;"><br />


<span class="c8 c2"><a>Discussion and Closing Remarks</a></span><br>
<br style="margin-bottom:1pt;"><br />


</td>
</tr>

</tbody>
</table>
</td>
</tr>
<tr>
<td><br></td>
</tr>


<!-- Keynotes -->
<tr valign="top">
<td width="70%" valign="top">

<h2><a id="keynotes">Keynotes</a></h2>
<p>

<table border="0" cellpadding="0" cellspacing="0">
<tbody font-weight: bold;>
<tr>
<img src="https://isis.vanderbilt.edu/sites/isis.vanderbilt.edu/files/styles/large/public/pictures/2022-06/taylor.jpeg" width="15%"><br>
<!-- <img src="http://www.taylortjohnson.com/?m=photo" width="15%"><br> -->
<b>From Neural Network Verification to Formal Verification for Neuro-Symbolic Artificial Intelligence (AI)</b><br>
<a href="http://www.taylortjohnson.com/"> Taylor T. Johnson</a>, Associate Professor, Computer Science, Vanderbilt University, USA

<br>
<br>
<b>Abstract:</b> The ongoing renaissance in artificial intelligence (AI) has led to the advent of data-driven machine learning (ML) methods deployed within components for sensing, perception, actuation, and control in safety-critical cyber-physical systems (CPS). While such learning-enabled components (LECs) are enabling autonomy in systems such as autonomous vehicles and robots, ensuring such components operate reliably in all scenarios is extraordinarily challenging, as demonstrated in part through recent accidents in semi-autonomous/autonomous CPS and by adversarial ML attacks. We will discuss formal methods for assuring specifications---mostly robustness and safety---in autonomous CPS and subcomponents thereof using our software tools <a href="https://github.com/verivital/nnv" target="_blank">NNV</a> and <a href="https://github.com/verivital/veritex" target="_blank">Veritex</a>, developed partly in DARPA Assured Autonomy and Assured Neuro Symbolic Learning and Reasoning (ANSR) projects. These methods have been evaluated in CPS development with multiple industry partners in automotive, aerospace, and robotics domains, and allow for formally analyzing neural networks and their usage in closed-loop systems. We will then discuss how these methods are enabling verification for the third wave of AI systems, namely neuro-symbolic systems. In particular, we will discuss a class of neuro-symbolic systems we have been developing called neuro-symbolic behavior trees (NSBTs), which are behavior trees (a form of hierarchical state machine) that may call neural networks and are becoming more widely used in robotics, and for which we have been developing verification methods implemented in a tool called <a href="https://github.com/verivital/behaverify" target="_blank">BehaVerify</a>. We will also discuss relevant ongoing community activities we help organize, such as the Verification of Neural Networks Competition (VNN-COMP) held with the International Conference on Computer-Aided Verification (CAV) the past few years and the Symposium on AI Verification (SAIV) this year, as well as the AI and Neural Network Control Systems (AINNCS) category of the hybrid systems verification competition (ARCH-COMP) also held the past few years. We will conclude with a discussion of future directions in the broader safe and trustworthy AI domain, such as in new projects verifying neural networks used in medical imaging analysis and malware classifiers.

<br>
<br>
<b>Speaker Bio:</b> Dr. Taylor T. Johnson, PE, is A. James and Alice B. Clark Foundation Chancellor Faculty Fellow and an Associate Professor of Computer Science (CS) in the School of Engineering (VUSE) at Vanderbilt University, where he directs the Verification and Validation for Intelligent and Trustworthy Autonomy Laboratory (VeriVITAL) and is a Senior Research Scientist in the Institute for Software Integrated Systems (ISIS). Dr. Johnson's research has been published in venues such as AAAI, CAV, EMSOFT, FM, FORMATS, HSCC, ICSE, ICDM, ICCPS, IJCAI, NFM, RTSS, SEFM, STTT, TNNLS, UAI, among others. Dr. Johnson earned a PhD in Electrical and Computer Engineering (ECE) from the University of Illinois at Urbana-Champaign in 2013, where he worked in the Coordinated Science Laboratory with Prof. Sayan Mitra, and a BSEE from Rice University in 2008. Dr. Johnson is a 2023 recipient  of an Outstanding Reviewer award at EMSOFT, 2022 recipient of the Best Artifact Evaluation Award at FORMATS, a 2018 and 2016 recipient of the Air Force Office of Scientific Research (AFOSR) Young Investigator Program (YIP) award, a 2016 recipient of the ACM Best Software Repeatability Award at HSCC, a 2015 recipient of the National Science Foundation (NSF) Computer and Information Science and Engineering (CISE) Research Initiation Initiative (CRII), and his group's research is or has recently been supported by AFOSR, ARO, AFRL, DARPA, Mathworks, NSA, NSF, NVIDIA, ONR, Toyota, and USDOT.

<br>
<br>
</tr>

<tr>
<img src="https://its-ss-academicportal.s3.amazonaws.com/prod/uqresearchers/photo/24584.jpeg" width="15%"><br>
<b>Machine Learning for Privacy Compliance in Software Ecosystems</b><br>
<a href="https://baigd.github.io/"> Guangdong Bai</a>, Associate Professor, The University of Queensland, Australia
<br>
<br>
<b>Abstract:</b> In recent years, many countries have implemented legislation to regulate the collection, use and sharing of personal data. These regulations have imposed stringent obligations on data controllers and data processors, with significant penalties for any infringement of user privacy. In this talk, we will highlight our recent progress in assessing privacy compliance in modern applications, focusing on our studies conducted on the Internet of Things (IoT), Android, and Virtual Personal Assistant (VPA) apps. We explore the role of machine learning techniques in these endeavors. We will introduce the analysis of privacy-related documents using natural language processing and machine learning, and the automatic understanding of data handling practices using software analytics. Furthermore, we will discuss the research opportunities facilitated by advanced large language models in understanding user opinions and nudging developers in addressing evolving privacy challenges. Through our work, we aim to foster a machine learning-enhanced privacy-fair environment for both application users and developers.
	
<br>
<br>
<b>Speaker Bio:</b> Guangdong Bai is an Associate Professor in the School of Electrical Engineering and Computer Science at the University of Queensland, Australia. He obtained his PhD degree from the National University of Singapore in 2015. His research spans responsible machine learning, security, and privacy. His work has appeared in top security and software engineering venues such as IEEE S&P, NDSS, USENIX Security, ICSE, and FSE. He has served as program/general (co-)chair of international conferences such as NSS, ICECCS, and ICFEM. He is an Associate Editor of IEEE Transactions on Dependable and Secure Computing.

<br>
<br>
</tr>
</tbody>
</table>
</td>
<td rowspan=3>



</table>
</div>
</body>

</html>
